# Self Supervision in Graph Neural Networks for Text Classification

Objective: The primary aim of this project was to explore the potential benefits of employing self-supervised learning approaches, particularly contrastive learning and various data augmentation techniques, on Graph Neural Networks (GNNs) to ascertain whether these methodologies enhance the performance in text classification tasks. The underlying hypothesis driving this experimentation was that the generation of contrastive examples from existing sentences could bolster the robustness of our model, enabling a more effective learning of sentence representations. This, in turn, would facilitate a better differentiation between sentences exhibiting similar structural attributes but diverging in semantic meaning.

Running the Classifer:

- Refer to the "run_classifier.ipynb" file regarding it

Final Report: Refer to the following files to get detailed information about the project:

- "Self Supervision in Graph Neural Networks for Text Classification.pdf"
- "Presentation.pdf"

Timeline of Work:
Oct 2022 - Dec 2022
