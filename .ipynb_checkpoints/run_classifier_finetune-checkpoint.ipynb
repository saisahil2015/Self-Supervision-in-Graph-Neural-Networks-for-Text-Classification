{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from datasets import load_datasets_and_vocabs, my_collate\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from tree import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\google\\api_core\\exceptions.py:37: ImportWarning: Please install grpcio-status to obtain helpful grpc error messages.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\botocore\\httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext\n",
      "D:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:228: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  interpolation: int = Image.BILINEAR,\n",
      "D:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:295: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  interpolation: int = Image.NEAREST,\n",
      "D:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:311: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  interpolation: int = Image.NEAREST,\n",
      "D:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:328: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  interpolation: int = Image.BICUBIC,\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import argparse\n",
    "import codecs\n",
    "import json\n",
    "import linecache\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import simplejson as json\n",
    "import torch\n",
    "from allennlp.modules.elmo import batch_to_ids\n",
    "from lxml import etree\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "\n",
    "def load_datasets_and_vocabs(args):\n",
    "    train, test = get_dataset(args.dataset_name)\n",
    "\n",
    "    # Our model takes unrolled data, currently we don't consider the MAMS cases(future experiments)\n",
    "    train_all_unrolled = get_rolled_and_unrolled_data(train, args)\n",
    "    test_all_unrolled = get_rolled_and_unrolled_data(test, args)\n",
    "\n",
    "    print(\"Size of the train dataset: {}\".format(len(train_all_unrolled)))\n",
    "    print(\"Size of the test dataset: {}\".format(len(test_all_unrolled)))\n",
    "    print(\"Printing all unrolled\")\n",
    "    print(train_all_unrolled[:2])\n",
    "\n",
    "    # Build word vocabulary(part of speech, dep_tag) and save pickles.\n",
    "    word_vecs, word_vocab, dep_tag_vocab, pos_tag_vocab = load_and_cache_vocabs(train_all_unrolled+test_all_unrolled, args)\n",
    "\n",
    "    embedding = torch.from_numpy(np.asarray(word_vecs, dtype=np.float32))\n",
    "    args.glove_embedding = embedding\n",
    "\n",
    "    train_dataset = ASBA_Depparsed_Dataset(train_all_unrolled, args, word_vocab, dep_tag_vocab, pos_tag_vocab)\n",
    "    \n",
    "    test_dataset = ASBA_Depparsed_Dataset(test_all_unrolled, args, word_vocab, dep_tag_vocab, pos_tag_vocab)\n",
    "\n",
    "    return train_dataset, test_dataset, word_vocab, dep_tag_vocab, pos_tag_vocab\n",
    "\n",
    "\n",
    "def read_sentence_depparsed(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        return data\n",
    "\n",
    "\n",
    "def get_dataset(dataset_name):\n",
    "    '''\n",
    "    Already preprocess the data and now they are in json format.(only for semeval14)\n",
    "    Retrieve train and test set\n",
    "    With a list of dict:\n",
    "    e.g. {\"sentence\": \"Boot time is super fast, around anywhere from 35 seconds to 1 minute.\",\n",
    "    \"tokens\": [\"Boot\", \"time\", \"is\", \"super\", \"fast\", \",\", \"around\", \"anywhere\", \"from\", \"35\", \"seconds\", \"to\", \"1\", \"minute\", \".\"],\n",
    "    \"tags\": [\"NNP\", \"NN\", \"VBZ\", \"RB\", \"RB\", \",\", \"RB\", \"RB\", \"IN\", \"CD\", \"NNS\", \"IN\", \"CD\", \"NN\", \".\"],\n",
    "    \"predicted_dependencies\": [\"nn\", \"nsubj\", \"root\", \"advmod\", \"advmod\", \"punct\", \"advmod\", \"advmod\", \"prep\", \"num\", \"pobj\", \"prep\", \"num\", \"pobj\", \"punct\"],\n",
    "    \"predicted_heads\": [2, 3, 0, 5, 3, 5, 8, 5, 8, 11, 9, 9, 14, 12, 3],\n",
    "    \"dependencies\": [[\"nn\", 2, 1], [\"nsubj\", 3, 2], [\"root\", 0, 3], [\"advmod\", 5, 4], [\"advmod\", 3, 5], [\"punct\", 5, 6], [\"advmod\", 8, 7], [\"advmod\", 5, 8],\n",
    "                    [\"prep\", 8, 9], [\"num\", 11, 10], [\"pobj\", 9, 11], [\"prep\", 9, 12], [\"num\", 14, 13], [\"pobj\", 12, 14], [\"punct\", 3, 15]],\n",
    "    \"aspect_sentiment\": [[\"Boot time\", \"positive\"]], \"from_to\": [[0, 2]]}\n",
    "    '''\n",
    "    rest_train = 'data/semeval14/Restaurants_Train_v2_biaffine_depparsed_with_energy.json'\n",
    "    rest_test = 'data/semeval14/Restaurants_Test_Gold_biaffine_depparsed_with_energy.json'\n",
    "\n",
    "    laptop_train = 'data/semeval14/Laptop_Train_v2_biaffine_depparsed.json'\n",
    "    laptop_test = 'data/semeval14/Laptops_Test_Gold_biaffine_depparsed.json'\n",
    "\n",
    "    twitter_train = 'data/twitter/train_biaffine.json'\n",
    "    twitter_test = 'data/twitter/test_biaffine.json'\n",
    "    print(\"Using the dataset: {}\".format(dataset_name))\n",
    "    ds_train = {'rest': rest_train,\n",
    "                'laptop': laptop_train, \n",
    "                'twitter': twitter_train}\n",
    "    ds_test = {'rest': rest_test,\n",
    "               'laptop': laptop_test, \n",
    "               'twitter': twitter_test}\n",
    "\n",
    "    train = list(read_sentence_depparsed(ds_train[dataset_name]))\n",
    "    test = list(read_sentence_depparsed(ds_test[dataset_name]))\n",
    "    \n",
    "    print(\"Read {} Train set: {}\".format(dataset_name, len(train)))\n",
    "    print(\"Read {} Test set: {}\".format(dataset_name, len(test)))\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def reshape_dependency_tree(as_start, as_end, dependencies, tokens=None, max_hop = 5):\n",
    "    '''\n",
    "    Adding multi hops\n",
    "    This function is at the core of our algo, it reshape the dependency tree and center on the aspect.\n",
    "    In open-sourced edition, I choose not to take energy(the soft prediction of dependency from parser)\n",
    "    into consideration. For it requires tweaking allennlp's source code, and the energy is space-consuming.\n",
    "    And there are no significant difference in performance between the soft and the hard(with non-connect) version.\n",
    "\n",
    "    '''\n",
    "    dep_tag = []\n",
    "    dep_idx = []\n",
    "    dep_dir = []\n",
    "    # 1 hop\n",
    "\n",
    "    for i in range(as_start, as_end):\n",
    "        for dep in dependencies:\n",
    "            if i == dep[1] - 1:\n",
    "                # not root, not aspect\n",
    "                if (dep[2] - 1 < as_start or dep[2] - 1 >= as_end) and dep[2] != 0 and dep[2] - 1 not in dep_idx:\n",
    "                    if str(dep[0]) != 'punct':  # and tokens[dep[2] - 1] not in stopWords\n",
    "                        dep_tag.append(dep[0])\n",
    "                        dep_dir.append(1)\n",
    "                    else:\n",
    "                        dep_tag.append('<pad>')\n",
    "                        dep_dir.append(0)\n",
    "                    dep_idx.append(dep[2] - 1)\n",
    "            elif i == dep[2] - 1:\n",
    "                # not root, not aspect\n",
    "                if (dep[1] - 1 < as_start or dep[1] - 1 >= as_end) and dep[1] != 0 and dep[1] - 1 not in dep_idx:\n",
    "                    if str(dep[0]) != 'punct':  # and tokens[dep[1] - 1] not in stopWords\n",
    "                        dep_tag.append(dep[0])\n",
    "                        dep_dir.append(2)\n",
    "                    else:\n",
    "                        dep_tag.append('<pad>')\n",
    "                        dep_dir.append(0)\n",
    "                    dep_idx.append(dep[1] - 1)\n",
    "\n",
    "    # add aspect and index, to make sure length matches len(tokens)\n",
    "    for idx, token in enumerate(tokens):\n",
    "        if idx not in dep_idx:\n",
    "            dep_tag.append('<pad>')\n",
    "            dep_dir.append(0)\n",
    "            dep_idx.append(idx)\n",
    "\n",
    "    index = [i[0] for i in sorted(enumerate(dep_idx), key=lambda x:x[1])]\n",
    "    dep_tag = [dep_tag[i] for i in index]\n",
    "    dep_idx = [dep_idx[i] for i in index]\n",
    "    dep_dir = [dep_dir[i] for i in index]\n",
    "\n",
    "    assert len(tokens) == len(dep_idx), 'length wrong'\n",
    "    return dep_tag, dep_idx, dep_dir\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_rolled_and_unrolled_data(input_data, args):\n",
    "    '''\n",
    "    In input_data, each sentence could have multiple aspects with different sentiments.\n",
    "    Our method treats each sentence with one aspect at a time, so even for\n",
    "    multi-aspect-multi-sentiment sentences, we will unroll them to single aspect sentence.\n",
    "\n",
    "    Perform reshape_dependency_tree to each sentence with aspect\n",
    "\n",
    "    return:\n",
    "        all_rolled:\n",
    "                a list of dict\n",
    "                    {sentence, tokens, pos_tags, pos_class, aspects(list of aspects), sentiments(list of sentiments)\n",
    "                    froms, tos, dep_tags, dep_index, dependencies}\n",
    "        all_unrolled:\n",
    "                unrolled, with aspect(single), sentiment(single) and so on...\n",
    "        mixed_rolled:\n",
    "                Multiple aspects and multiple sentiments, ROLLED.\n",
    "        mixed_unrolled:\n",
    "                Multiple aspects and multiple sentiments, UNROLLED.\n",
    "    '''\n",
    "    # A hand-picked set of part of speech tags that we see contributes to ABSA.\n",
    "    opinionated_tags = ['JJ', 'JJR', 'JJS', 'RB', 'RBR',\n",
    "                        'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "    all_rolled = []\n",
    "    all_unrolled = []\n",
    "    mixed_rolled = []\n",
    "    mixed_unrolled = []\n",
    "\n",
    "    unrolled = []\n",
    "    mixed = []\n",
    "    unrolled_ours = []\n",
    "    mixed_ours = []\n",
    "\n",
    "    # Make sure the tree is successfully built.\n",
    "    zero_dep_counter = 0\n",
    "\n",
    "    # Sentiment counters\n",
    "    total_counter = defaultdict(int)\n",
    "    mixed_counter = defaultdict(int)\n",
    "    sentiments_lookup = {'negative': 0, 'positive': 1, 'neutral': 2}\n",
    "\n",
    "    tree_samples = []\n",
    "    # for seeking 'but' examples\n",
    "    for e in input_data:\n",
    "        e['tokens'] = [x.lower() for x in e['tokens']]\n",
    "        aspects = []\n",
    "        sentiments = []\n",
    "        froms = []\n",
    "        tos = []\n",
    "        dep_tags = []\n",
    "        dep_index = []\n",
    "        dep_dirs = []\n",
    "\n",
    "        # Classify based on POS-tags\n",
    "\n",
    "        pos_class = e['tags']\n",
    "\n",
    "        # Iterate through aspects in a sentence and reshape the dependency tree.\n",
    "        for i in range(len(e['aspect_sentiment'])):\n",
    "            aspect = e['aspect_sentiment'][i][0].lower()\n",
    "            # We would tokenize the aspect while at it.\n",
    "            aspect = word_tokenize(aspect)\n",
    "            sentiment = sentiments_lookup[e['aspect_sentiment'][i][1]]\n",
    "            frm = e['from_to'][i][0]\n",
    "            to = e['from_to'][i][1]\n",
    "\n",
    "            aspects.append(aspect)\n",
    "            sentiments.append(sentiment)\n",
    "            froms.append(frm)\n",
    "            tos.append(to)\n",
    "\n",
    "            # Center on the aspect.\n",
    "            dep_tag, dep_idx, dep_dir = reshape_dependency_tree(frm, to, e['dependencies'], tokens=e['tokens'], max_hop=args.max_hop)\n",
    "\n",
    "            # Because of tokenizer differences, aspect opsitions are off, so we find the index and try again.\n",
    "            if len(dep_tag) == 0:\n",
    "                zero_dep_counter += 1\n",
    "                as_sent = e['aspect_sentiment'][i][0].split()\n",
    "                as_start = e['tokens'].index(as_sent[0])\n",
    "                # print(e['tokens'], e['aspect_sentiment'], e['dependencies'],as_sent[0])\n",
    "                as_end = e['tokens'].index(\n",
    "                    as_sent[-1]) if len(as_sent) > 1 else as_start + 1\n",
    "                print(\"Debugging: as_start as_end \", as_start, as_end)\n",
    "                dep_tag, dep_idx, dep_dir = reshape_dependency_tree(as_start, as_end, e['dependencies'], tokens=e['tokens'], max_hop=args.max_hop)\n",
    "                if len(dep_tag) == 0:  # for debugging\n",
    "                    print(\"Debugging: zero_dep\",\n",
    "                          e['aspect_sentiment'][i][0], e['tokens'])\n",
    "                    print(\"Debugging: \". e['dependencies'])\n",
    "                else:\n",
    "                    zero_dep_counter -= 1\n",
    "\n",
    "            dep_tags.append(dep_tag)\n",
    "            dep_index.append(dep_idx)\n",
    "            dep_dirs.append(dep_dir)\n",
    "\n",
    "            total_counter[e['aspect_sentiment'][i][1]] += 1\n",
    "\n",
    "            # Unrolling\n",
    "            all_unrolled.append(\n",
    "                {'sentence': e['tokens'], 'tags': e['tags'], 'pos_class': pos_class, 'aspect': aspect, 'sentiment': sentiment,\n",
    "                    'predicted_dependencies': e['predicted_dependencies'], 'predicted_heads': e['predicted_heads'],\n",
    "                 'from': frm, 'to': to, 'dep_tag': dep_tag, 'dep_idx': dep_idx, 'dep_dir':dep_dir,'dependencies': e['dependencies']})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return all_unrolled\n",
    "\n",
    "import pickle\n",
    "\n",
    "def load_and_cache_vocabs(data, args):\n",
    "    '''\n",
    "    Build vocabulary of words, part of speech tags, dependency tags and cache them.\n",
    "    Load glove embedding if needed.'''\n",
    "    \n",
    "    if True:\n",
    "        with open(\"cached_word_vocab.pkl\", 'rb') as f:\n",
    "            word_vocab = pickle.load(f)\n",
    "        \n",
    "        with open(\"cached_word_vecs.pkl\", 'rb') as f:\n",
    "            word_vecs = pickle.load(f)\n",
    "        \n",
    "        with open(\"cached_dep_tag_vocab.pkl\", 'rb') as f:\n",
    "            dep_tag_vocab = pickle.load(f)\n",
    "            \n",
    "        with open(\"cached_pos_tag_vocab.pkl\", 'rb') as f:\n",
    "            pos_tag_vocab = pickle.load(f)\n",
    "        #pos_tag_vocab = build_pos_tag_vocab(data, min_freq=0)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Build or load word vocab and glove embeddings.\n",
    "        word_vocab = build_text_vocab(data)\n",
    "        print('Word vocab size: {}'.format(word_vocab['len']))\n",
    "        with open(\"cached_word_vocab.pkl\", 'wb') as f:\n",
    "            pickle.dump(word_vocab, f, -1)\n",
    "        \n",
    "        word_vecs = load_glove_embedding(word_vocab['itos'], args.glove_dir, 0.25, args.embedding_dim)\n",
    "        print('Word vecs size')\n",
    "        with open(\"cached_word_vecs.pkl\", 'wb') as f:\n",
    "            pickle.dump(word_vecs, f, -1)\n",
    "            \n",
    "        # Build vocab of dependency tags\n",
    "        dep_tag_vocab = build_dep_tag_vocab(data, min_freq=0)\n",
    "        print('dep_tag_vocab size: {}'.format(dep_tag_vocab['len']))\n",
    "        with open(\"cached_dep_tag_vocab.pkl\", 'wb') as f:\n",
    "            pickle.dump(dep_tag_vocab, f, -1)\n",
    "            \n",
    "        # Build vocab of part of speech tags.\n",
    "        pos_tag_vocab = build_pos_tag_vocab(data, min_freq=0)\n",
    "        print('pos_tag_vocab size: {}'.format(pos_tag_vocab['len']))\n",
    "        with open(\"cached_pos_tag_vocab.pkl\", 'wb') as f:\n",
    "            pickle.dump(pos_tag_vocab, f, -1)\n",
    "\n",
    "    return word_vecs, word_vocab, dep_tag_vocab, pos_tag_vocab\n",
    "\n",
    "\n",
    "def load_glove_embedding(word_list, glove_dir, uniform_scale, dimension_size):\n",
    "    glove_words = []\n",
    "    with open(os.path.join(glove_dir, 'glove.840B.300d.txt'), 'r', encoding=\"utf8\") as fopen:\n",
    "        for line in fopen:\n",
    "            glove_words.append(line.strip().split(' ')[0])\n",
    "    word2offset = {w: i for i, w in enumerate(glove_words)}\n",
    "    word_vectors = []\n",
    "    for word in word_list:\n",
    "        if word in word2offset:\n",
    "            line = linecache.getline(os.path.join(\n",
    "                glove_dir, 'glove.840B.300d.txt'), word2offset[word]+1)\n",
    "            assert(word == line[:line.find(' ')].strip())\n",
    "            word_vectors.append(np.fromstring(\n",
    "                line[line.find(' '):].strip(), sep=' ', dtype=np.float32))\n",
    "        elif word == '<pad>':\n",
    "            word_vectors.append(np.zeros(dimension_size, dtype=np.float32))\n",
    "        else:\n",
    "            word_vectors.append(\n",
    "                np.random.uniform(-uniform_scale, uniform_scale, dimension_size))\n",
    "    return word_vectors\n",
    "\n",
    "\n",
    "def _default_unk_index():\n",
    "    return 1\n",
    "\n",
    "\n",
    "def build_text_vocab(data, vocab_size=100000, min_freq=2):\n",
    "    counter = Counter()\n",
    "    for d in data:\n",
    "        s = d['sentence']\n",
    "        counter.update(s)\n",
    "\n",
    "    itos = ['[PAD]', '[UNK]']\n",
    "    min_freq = max(min_freq, 1)\n",
    "\n",
    "    # sort by frequency, then alphabetically\n",
    "    words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n",
    "    words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    for word, freq in words_and_frequencies:\n",
    "        if freq < min_freq or len(itos) == vocab_size:\n",
    "            break\n",
    "        itos.append(word)\n",
    "    # stoi is simply a reverse dict for itos\n",
    "    stoi = defaultdict(_default_unk_index)\n",
    "    stoi.update({tok: i for i, tok in enumerate(itos)})\n",
    "\n",
    "    return {'itos': itos, 'stoi': stoi, 'len': len(itos)}\n",
    "\n",
    "\n",
    "def build_pos_tag_vocab(data, vocab_size=1000, min_freq=1):\n",
    "    \"\"\"\n",
    "    Part of speech tags vocab.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for d in data:\n",
    "        tags = d['tags']\n",
    "        counter.update(tags)\n",
    "\n",
    "    itos = ['<pad>']\n",
    "    min_freq = max(min_freq, 1)\n",
    "\n",
    "    # sort by frequency, then alphabetically\n",
    "    words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n",
    "    words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    for word, freq in words_and_frequencies:\n",
    "        if freq < min_freq or len(itos) == vocab_size:\n",
    "            break\n",
    "        itos.append(word)\n",
    "    # stoi is simply a reverse dict for itos\n",
    "    stoi = defaultdict()\n",
    "    stoi.update({tok: i for i, tok in enumerate(itos)})\n",
    "\n",
    "    return {'itos': itos, 'stoi': stoi, 'len': len(itos)}\n",
    "\n",
    "\n",
    "\n",
    "def build_dep_tag_vocab(data, vocab_size=1000, min_freq=0):\n",
    "    counter = Counter()\n",
    "    for d in data:\n",
    "        tags = d['dep_tag']\n",
    "        counter.update(tags)\n",
    "\n",
    "    itos = ['<pad>', '<unk>']\n",
    "    min_freq = max(min_freq, 1)\n",
    "\n",
    "    # sort by frequency, then alphabetically\n",
    "    words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n",
    "    words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    for word, freq in words_and_frequencies:\n",
    "        if freq < min_freq or len(itos) == vocab_size:\n",
    "            break\n",
    "        if word == '<pad>':\n",
    "            continue\n",
    "        itos.append(word)\n",
    "    # stoi is simply a reverse dict for itos\n",
    "    stoi = defaultdict(_default_unk_index)\n",
    "    stoi.update({tok: i for i, tok in enumerate(itos)})\n",
    "\n",
    "    return {'itos': itos, 'stoi': stoi, 'len': len(itos)}\n",
    "\n",
    "\n",
    "class ASBA_Depparsed_Dataset(Dataset):\n",
    "    def __init__(self, data, args, word_vocab, dep_tag_vocab, pos_tag_vocab):\n",
    "        self.data = data\n",
    "        self.args = args\n",
    "        self.word_vocab = word_vocab\n",
    "        self.dep_tag_vocab = dep_tag_vocab\n",
    "        self.pos_tag_vocab = pos_tag_vocab\n",
    "\n",
    "        self.convert_features()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        items = e['dep_tag_ids'], e['pos_class'], e['text_len'], e['aspect_len'], e['sentiment'], e['dep_rel_ids'], e['predicted_heads'], e['aspect_position'], e['dep_dir_ids']\n",
    "        non_bert_items = e['sentence_ids'], e['aspect_ids']\n",
    "        items_tensor = non_bert_items + items\n",
    "        items_tensor = tuple(torch.tensor(t) for t in items_tensor)\n",
    "\n",
    "        return items_tensor\n",
    "\n",
    "    \n",
    "\n",
    "    def convert_features(self):\n",
    "        '''\n",
    "        Convert sentence, aspects, pos_tags, dependency_tags to ids.\n",
    "        '''\n",
    "        for i in range(len(self.data)):\n",
    "       \n",
    "            self.data[i]['sentence_ids'] = [self.word_vocab['stoi'][w] for w in self.data[i]['sentence']]\n",
    "            self.data[i]['aspect_ids'] = [self.word_vocab['stoi'][w] for w in self.data[i]['aspect']]\n",
    "           \n",
    "\n",
    "            self.data[i]['text_len'] = len(self.data[i]['sentence'])\n",
    "            self.data[i]['aspect_position'] = [0] * self.data[i]['text_len']\n",
    "            try:  # find the index of aspect in sentence\n",
    "                for j in range(self.data[i]['from'], self.data[i]['to']):\n",
    "                    self.data[i]['aspect_position'][j] = 1\n",
    "            except:\n",
    "                for term in self.data[i]['aspect']:\n",
    "                    self.data[i]['aspect_position'][self.data[i]\n",
    "                                                    ['sentence'].index(term)] = 1\n",
    "\n",
    "            self.data[i]['dep_tag_ids'] = [self.dep_tag_vocab['stoi'][w]\n",
    "                                           for w in self.data[i]['dep_tag']]\n",
    "            self.data[i]['dep_dir_ids'] = [idx\n",
    "                                           for idx in self.data[i]['dep_dir']]\n",
    "            self.data[i]['pos_class'] = [self.pos_tag_vocab['stoi'][w]\n",
    "                                             for w in self.data[i]['tags']]\n",
    "            self.data[i]['aspect_len'] = len(self.data[i]['aspect'])\n",
    "\n",
    "            self.data[i]['dep_rel_ids'] = [self.dep_tag_vocab['stoi'][r]\n",
    "                                           for r in self.data[i]['predicted_dependencies']]\n",
    "\n",
    "\n",
    "def my_collate(batch):\n",
    "    '''\n",
    "    Pad sentence and aspect in a batch.\n",
    "    Sort the sentences based on length.\n",
    "    Turn all into tensors.\n",
    "    '''\n",
    "    sentence_ids, aspect_ids, dep_tag_ids, pos_class, text_len, aspect_len, sentiment, dep_rel_ids, dep_heads, aspect_positions, dep_dir_ids = zip(\n",
    "        *batch)  # from Dataset.__getitem__()\n",
    "    text_len = torch.tensor(text_len)\n",
    "    aspect_len = torch.tensor(aspect_len)\n",
    "    sentiment = torch.tensor(sentiment)\n",
    "\n",
    "    # Pad sequences.\n",
    "    sentence_ids = pad_sequence(\n",
    "        sentence_ids, batch_first=True, padding_value=0)\n",
    "    aspect_ids = pad_sequence(aspect_ids, batch_first=True, padding_value=0)\n",
    "    aspect_positions = pad_sequence(\n",
    "        aspect_positions, batch_first=True, padding_value=0)\n",
    "\n",
    "    dep_tag_ids = pad_sequence(dep_tag_ids, batch_first=True, padding_value=0)\n",
    "    dep_dir_ids = pad_sequence(dep_dir_ids, batch_first=True, padding_value=0)\n",
    "    pos_class = pad_sequence(pos_class, batch_first=True, padding_value=0)\n",
    "\n",
    "    dep_rel_ids = pad_sequence(dep_rel_ids, batch_first=True, padding_value=0)\n",
    "    dep_heads = pad_sequence(dep_heads, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Sort all tensors based on text len.\n",
    "    _, sorted_idx = text_len.sort(descending=True)\n",
    "    sentence_ids = sentence_ids[sorted_idx]\n",
    "    aspect_ids = aspect_ids[sorted_idx]\n",
    "    aspect_positions = aspect_positions[sorted_idx]\n",
    "    dep_tag_ids = dep_tag_ids[sorted_idx]\n",
    "    dep_dir_ids = dep_dir_ids[sorted_idx]\n",
    "    pos_class = pos_class[sorted_idx]\n",
    "    text_len = text_len[sorted_idx]\n",
    "    aspect_len = aspect_len[sorted_idx]\n",
    "    sentiment = sentiment[sorted_idx]\n",
    "    dep_rel_ids = dep_rel_ids[sorted_idx]\n",
    "    dep_heads = dep_heads[sorted_idx]\n",
    "\n",
    "    return sentence_ids, aspect_ids, dep_tag_ids, pos_class, text_len, aspect_len, sentiment, dep_rel_ids, dep_heads, aspect_positions, dep_dir_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_logits(target, mask):\n",
    "    return target * mask + (1 - mask) * (-1e30)\n",
    "\n",
    "class Gating(nn.Module):\n",
    "    def __init__(self, layer_num, dim):\n",
    "        super().__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.linear = nn.ModuleList([nn.Linear(dim, dim) for _ in range(layer_num)])\n",
    "        self.gate = nn.ModuleList([nn.Linear(dim, dim) for _ in range(layer_num)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.layer_num):\n",
    "            gate = torch.sigmoid(self.gate[i](x))\n",
    "            nonlinear = F.relu(self.linear[i](x))\n",
    "            x = gate * nonlinear + (1 - gate) * x\n",
    "        return x\n",
    "\n",
    "class DotprodAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, feature, dep_tags, dmask):\n",
    "        '''\n",
    "        C feature/context [N, L, D]\n",
    "        Q dep_tags_v          [N, D]\n",
    "        mask dmask          [N, L]\n",
    "        '''\n",
    "\n",
    "        Q = dep_tags\n",
    "        Q = Q.unsqueeze(2)  # (N, D, 1)\n",
    "        dot_prod = torch.bmm(feature, Q)  # (N, L, 1)\n",
    "        dmask = dmask.unsqueeze(2)  # (N, D, 1)\n",
    "        attention_weight = mask_logits(dot_prod, dmask)  # (N, L ,1)\n",
    "        attention = F.softmax(attention_weight, dim=1)  # (N, L, 1)\n",
    "\n",
    "        out = torch.bmm(feature.transpose(1, 2), attention)  # (N, D, 1)\n",
    "        out = out.squeeze(2)\n",
    "        out = torch.sigmoid(out)\n",
    "        # (N, D), ([N, L]), (N, L, 1)\n",
    "        return out\n",
    "\n",
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_dim = 300, hidden_dim = 64):\n",
    "        # in_dim: the dimension fo query vector\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, feature, dep_tags_v, dmask):\n",
    "        '''\n",
    "        C feature/context [N, L, D]\n",
    "        Q dep_tags_v          [N, L, D]\n",
    "        mask dmask          [N, L]\n",
    "        '''\n",
    "        Q = self.fc1(dep_tags_v)\n",
    "        Q = self.relu(Q)\n",
    "        Q = self.fc2(Q)  # (N, L, 1)\n",
    "        Q = Q.squeeze(2)\n",
    "        Q = F.softmax(mask_logits(Q, dmask), dim=1)\n",
    "\n",
    "        Q = Q.unsqueeze(2)\n",
    "        out = torch.bmm(feature.transpose(1, 2), Q)\n",
    "        out = out.squeeze(2)\n",
    "        # out = F.sigmoid(out)\n",
    "        return out  # ([N, L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGraphAttentionNetwork(nn.Module):\n",
    "    def __init__(self, args, dep_tag_num):\n",
    "        super(TextGraphAttentionNetwork, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        num_embeddings, embed_dim = args.glove_embedding.shape\n",
    "        self.embed = nn.Embedding(num_embeddings, embed_dim)\n",
    "        self.embed.weight = nn.Parameter(args.glove_embedding, requires_grad=False)\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.gate = Gating(args.num_layers, args.embedding_dim)\n",
    "        self.rnn = nn.GRU(input_size=args.embedding_dim, hidden_size=args.hidden_size, bidirectional=True, batch_first=True, num_layers=args.num_layers)\n",
    "    \n",
    "        self.gat = [DotprodAttention().to(args.device) for i in range(args.num_heads)]\n",
    "        self.gat_dep = [RelationAttention(in_dim = args.embedding_dim).to(args.device) for i in range(args.num_heads)]\n",
    "        \n",
    "        last_hidden_size = args.hidden_size*4\n",
    "\n",
    "        layers = [nn.Linear(last_hidden_size, args.final_hidden_size), nn.ReLU()]\n",
    "        \n",
    "        for _ in range(args.num_mlps-1):\n",
    "            layers += [nn.Linear(args.final_hidden_size, args.final_hidden_size), nn.ReLU()]\n",
    "            \n",
    "        self.dep_embed = nn.Embedding(dep_tag_num, args.embedding_dim)\n",
    "        gcn_input_dim = args.hidden_size * 2\n",
    "        self.fc = nn.Linear(args.embedding_dim, 2*args.hidden_size)\n",
    "        self.fcs = nn.Sequential(*layers)\n",
    "        self.fc_final = nn.Linear(args.final_hidden_size, args.num_classes)\n",
    "        self.linear = nn.Linear(gcn_input_dim, gcn_input_dim)\n",
    "\n",
    "    def forward(self, sentence, aspect, pos_class, dep_tags, text_len, aspect_len, dep_rels, dep_heads, aspect_position, dep_dirs):\n",
    "\n",
    "        '''\n",
    "        Forward takes:\n",
    "            sentence: sentence_id of size (batch_size, text_length)\n",
    "            aspect: aspect_id of size (batch_size, aspect_length)\n",
    "            pos_class: pos_tag_id of size (batch_size, text_length)\n",
    "            dep_tags: dep_tag_id of size (batch_size, text_length)\n",
    "            text_len: (batch_size,) length of each sentence\n",
    "            aspect_len: (batch_size, ) aspect length of each sentence\n",
    "            dep_rels: (batch_size, text_length) relation\n",
    "            dep_heads: (batch_size, text_length) which node adjacent to that node\n",
    "            aspect_position: (batch_size, text_length) mask, with the position of aspect as 1 and others as 0\n",
    "            dep_dirs: (batch_size, text_length) the directions each node to the aspect\n",
    "        '''\n",
    "        fmask = (torch.zeros_like(sentence) != sentence).float()  # (N，L)\n",
    "        feature = self.embed(sentence)  # (N, L, D)\n",
    "        feature = self.dropout(feature)\n",
    "        feature = self.gate(feature)\n",
    "        feature = self.fc(feature) # (N,L,D)\n",
    "        \n",
    "        dep_feature = self.dep_embed(dep_tags) \n",
    "        dep_feature = self.gate(dep_feature)\n",
    "\n",
    "        dep_out = [g(feature, dep_feature, fmask).unsqueeze(1) for g in self.gat_dep] #(N, 1, D) * num_heads\n",
    "        dep_out = torch.cat(dep_out, dim = 1) # (N, H, D)\n",
    "        dep_out = dep_out.mean(dim = 1) # (N, D)\n",
    "        \n",
    "        #print(\"Shape of the feature\", feature.shape)\n",
    "        #print(\"Shape of the dep_out\", dep_out.shape)\n",
    "        \n",
    "        gat_out = self.linear(feature) # (N, L, D)\n",
    "        #print(\"Shape of the gat_out right now\", gat_out.shape)\n",
    "        fmask = fmask.unsqueeze(2)\n",
    "        gat_out = gat_out * fmask\n",
    "        \n",
    "        #print(\"Shape of the gat_out after fmask\", gat_out.shape)\n",
    "        gat_out = F.relu(torch.sum(gat_out, dim = 1)) # (N, D)\n",
    "        #print(\"Shape of the gat_out\", gat_out.shape)\n",
    "        \n",
    "        feature_out = torch.cat([dep_out,  gat_out], dim = 1) # (N, D')\n",
    "       \n",
    "        # feature_out = gat_out\n",
    "        #############################################################################################\n",
    "        x = self.dropout(feature_out)\n",
    "        x = self.fcs(x)\n",
    "        logit = self.fc_final(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "\n",
    "args = Parameters()\n",
    " # Required parameters\n",
    "args.dataset_name = 'laptop' # 'rest' 'laptop' 'twitter'\n",
    "args.output_dir = 'data/output-gcn'\n",
    "args.num_classes = 3\n",
    "args.cuda_id = '3'\n",
    "args.seed = 2022\n",
    "\n",
    "# Model parameters\n",
    "args.glove_dir = 'glove'\n",
    "args.num_layers = 2\n",
    "args.max_hop = 4\n",
    "args.num_heads = 6\n",
    "args.dropout = 0\n",
    "args.num_gcn_layers = 1\n",
    "args.gc_mem_dim = 300\n",
    "\n",
    "args.gcn_dropout = 0.2\n",
    "# GAT\n",
    "args.gat = True\n",
    "args.gat_out = True\n",
    "\n",
    "\n",
    "args.gat_attention_type = 'dotprod' # 'linear' 'dotprod' 'gcn'\n",
    "args.embedding_type = 'glove' # 'glove' 'bert'\n",
    "args.embedding_dim = 300\n",
    "args.dep_relation_embed_dim = 300\n",
    "args.hidden_size = 300\n",
    "args.final_hidden_size = 300\n",
    "args.num_mlps = 2\n",
    "# Training parameters\n",
    "args.per_gpu_train_batch_size = 16\n",
    "args.per_gpu_eval_batch_size = 32\n",
    "args.gradient_accumulation_steps = 2\n",
    "args.learning_rate = 1e-3\n",
    "args.weight_decay = 0.0\n",
    "args.adam_epsilon = 1e-8\n",
    "args.max_grad_norm = 1.0\n",
    "args.num_train_epochs = 30\n",
    "args.max_steps = -1\n",
    "args.logging_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_from_batch(args, batch):\n",
    "    # sentence_ids, aspect_ids, dep_tag_ids, pos_class, text_len, aspect_len, sentiment, dep_rel_ids, dep_heads, aspect_positions\n",
    "    inputs = {  'sentence': batch[0],\n",
    "                'aspect': batch[1], # aspect token\n",
    "                'dep_tags': batch[2], # reshaped\n",
    "                'pos_class': batch[3],\n",
    "                'text_len': batch[4],\n",
    "                'aspect_len': batch[5],\n",
    "                'dep_rels': batch[7], # adj no-reshape\n",
    "                'dep_heads': batch[8],\n",
    "                'aspect_position': batch[9],\n",
    "                'dep_dirs': batch[10]\n",
    "                }\n",
    "    labels = batch[6]\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "def train(args, train_dataset, model, eval_dataset):\n",
    "    '''Train the model'''\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size\n",
    "\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=my_collate)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "    parameters = filter(lambda param: param.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=args.learning_rate)\n",
    "\n",
    "    # Train\n",
    "    print(\"Started Training...\")\n",
    "    print(\"Num examples = {}\".format(len(train_dataset)))\n",
    "    print(\"Num Epochs = {}\".format(args.num_train_epochs))\n",
    "    print(\"Instantaneous batch size per GPU = {}\".format(args.per_gpu_train_batch_size))\n",
    "\n",
    "    all_eval_results = []\n",
    "\n",
    "    set_seed(args)\n",
    "\n",
    "    for epoch in range(args.num_train_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            model.zero_grad()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            inputs, labels = get_input_from_batch(args, batch)\n",
    "            logit = model(**inputs)\n",
    "            loss = F.cross_entropy(logit, labels)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0.0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "        for step, batch in enumerate(eval_dataloader):\n",
    "            with torch.no_grad():\n",
    "                batch = tuple(t.to(args.device) for t in batch)\n",
    "                inputs, labels = get_input_from_batch(args, batch)\n",
    "                logits = model(**inputs)\n",
    "                loss = F.cross_entropy(logits, labels)\n",
    "                eval_loss += loss.item()\n",
    "\n",
    "                if preds is None:\n",
    "                    preds = logits.detach().cpu().numpy()\n",
    "                    out_label_ids = labels.detach().cpu().numpy()\n",
    "                else:\n",
    "                    preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                    out_label_ids = np.append(out_label_ids, labels.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "   \n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        result = compute_metrics(preds, out_label_ids)\n",
    "    \n",
    "        result['train_loss'] = train_loss/len(train_dataloader)\n",
    "        result['eval_loss'] = eval_loss/len(eval_dataloader)\n",
    "        result['epoch'] = epoch\n",
    "\n",
    "        all_eval_results.append(result)\n",
    "        print(\"Epoch: {}; train_loss: {}; eval_loss: {}; eval_acc: {}; eval_f1: {}\".format(epoch + 1, np.round(train_loss/len(train_dataloader), 4), np.round(eval_loss/len(eval_dataloader), 4), np.round(result['acc'], 4), np.round(result['f1'], 4)))\n",
    "    \n",
    "    return all_eval_results\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    precision = precision_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "Using the dataset: laptop\n",
      "Read laptop Train set: 1462\n",
      "Read laptop Test set: 411\n",
      "Size of the train dataset: 2313\n",
      "Size of the test dataset: 638\n",
      "Printing all unrolled\n",
      "[{'sentence': ['i', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.'], 'tags': ['PRON', 'VERB', 'PRON', 'ADP', 'NOUN', 'CCONJ', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'SCONJ', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'PUNCT'], 'pos_class': ['PRON', 'VERB', 'PRON', 'ADP', 'NOUN', 'CCONJ', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'SCONJ', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'PUNCT'], 'aspect': ['cord'], 'sentiment': 2, 'predicted_dependencies': ['nsubj', 'root', 'dep', 'advmod', 'dep', 'nsubj', 'dep', 'dep', 'det', 'dobj', 'prep', 'dep', 'advmod', 'prep', 'dep', 'amod', 'nn', 'pobj', 'punct'], 'predicted_heads': [2, 0, 2, 2, 4, 7, 2, 7, 10, 8, 8, 11, 14, 12, 17, 17, 18, 14, 2], 'from': 9, 'to': 10, 'dep_tag': ['<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', 'dobj', 'det', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'dep_idx': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], 'dep_dir': [0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'dependencies': [['nsubj', 2, 1], ['root', 0, 2], ['dep', 2, 3], ['advmod', 2, 4], ['dep', 4, 5], ['nsubj', 7, 6], ['dep', 2, 7], ['dep', 7, 8], ['det', 10, 9], ['dobj', 8, 10], ['prep', 8, 11], ['dep', 11, 12], ['advmod', 14, 13], ['prep', 12, 14], ['dep', 17, 15], ['amod', 17, 16], ['nn', 18, 17], ['pobj', 14, 18], ['punct', 2, 19]]}, {'sentence': ['i', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.'], 'tags': ['PRON', 'VERB', 'PRON', 'ADP', 'NOUN', 'CCONJ', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'SCONJ', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'PUNCT'], 'pos_class': ['PRON', 'VERB', 'PRON', 'ADP', 'NOUN', 'CCONJ', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'SCONJ', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'PUNCT'], 'aspect': ['battery', 'life'], 'sentiment': 1, 'predicted_dependencies': ['nsubj', 'root', 'dep', 'advmod', 'dep', 'nsubj', 'dep', 'dep', 'det', 'dobj', 'prep', 'dep', 'advmod', 'prep', 'dep', 'amod', 'nn', 'pobj', 'punct'], 'predicted_heads': [2, 0, 2, 2, 4, 7, 2, 7, 10, 8, 8, 11, 14, 12, 17, 17, 18, 14, 2], 'from': 16, 'to': 18, 'dep_tag': ['<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', 'pobj', 'dep', 'amod', '<pad>', '<pad>', '<pad>'], 'dep_idx': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], 'dep_dir': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0], 'dependencies': [['nsubj', 2, 1], ['root', 0, 2], ['dep', 2, 3], ['advmod', 2, 4], ['dep', 4, 5], ['nsubj', 7, 6], ['dep', 2, 7], ['dep', 7, 8], ['det', 10, 9], ['dobj', 8, 10], ['prep', 8, 11], ['dep', 11, 12], ['advmod', 14, 13], ['prep', 12, 14], ['dep', 17, 15], ['amod', 17, 16], ['nn', 18, 17], ['pobj', 14, 18], ['punct', 2, 19]]}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'itos': ['<pad>',\n",
       "  '<unk>',\n",
       "  'dep',\n",
       "  'det',\n",
       "  'amod',\n",
       "  'prep',\n",
       "  'advmod',\n",
       "  'nsubj',\n",
       "  'pobj',\n",
       "  'nn',\n",
       "  'ccomp',\n",
       "  'mark',\n",
       "  'dobj',\n",
       "  'cc',\n",
       "  'cop',\n",
       "  'num',\n",
       "  'xcomp',\n",
       "  'advcl',\n",
       "  'aux',\n",
       "  'rcmod',\n",
       "  'csubj',\n",
       "  'discourse',\n",
       "  'neg',\n",
       "  'poss',\n",
       "  'conj',\n",
       "  'pcomp',\n",
       "  'tmod',\n",
       "  'quantmod',\n",
       "  'possessive',\n",
       "  'number',\n",
       "  'prt',\n",
       "  'acomp',\n",
       "  'parataxis',\n",
       "  'npadvmod',\n",
       "  'partmod',\n",
       "  'auxpass',\n",
       "  'expl',\n",
       "  'nsubjpass',\n",
       "  'infmod',\n",
       "  'iobj'],\n",
       " 'stoi': defaultdict(<function __main__._default_unk_index()>,\n",
       "             {'<pad>': 0,\n",
       "              '<unk>': 1,\n",
       "              'dep': 2,\n",
       "              'det': 3,\n",
       "              'amod': 4,\n",
       "              'prep': 5,\n",
       "              'advmod': 6,\n",
       "              'nsubj': 7,\n",
       "              'pobj': 8,\n",
       "              'nn': 9,\n",
       "              'ccomp': 10,\n",
       "              'mark': 11,\n",
       "              'dobj': 12,\n",
       "              'cc': 13,\n",
       "              'cop': 14,\n",
       "              'num': 15,\n",
       "              'xcomp': 16,\n",
       "              'advcl': 17,\n",
       "              'aux': 18,\n",
       "              'rcmod': 19,\n",
       "              'csubj': 20,\n",
       "              'discourse': 21,\n",
       "              'neg': 22,\n",
       "              'poss': 23,\n",
       "              'conj': 24,\n",
       "              'pcomp': 25,\n",
       "              'tmod': 26,\n",
       "              'quantmod': 27,\n",
       "              'possessive': 28,\n",
       "              'number': 29,\n",
       "              'prt': 30,\n",
       "              'acomp': 31,\n",
       "              'parataxis': 32,\n",
       "              'npadvmod': 33,\n",
       "              'partmod': 34,\n",
       "              'auxpass': 35,\n",
       "              'expl': 36,\n",
       "              'nsubjpass': 37,\n",
       "              'infmod': 38,\n",
       "              'iobj': 39,\n",
       "              'root': 1,\n",
       "              'punct': 1,\n",
       "              'mwe': 1,\n",
       "              'appos': 1,\n",
       "              'preconj': 1}),\n",
       " 'len': 40}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args.device = device\n",
    "print('Device is {}'.format(args.device))\n",
    "\n",
    "# Set seed\n",
    "set_seed(args)\n",
    "# Load datasets and vocabs\n",
    "train_dataset, test_dataset, word_vocab, dep_tag_vocab, pos_tag_vocab= load_datasets_and_vocabs(args)\n",
    "args.dep_tag_vocab_size = len(dep_tag_vocab['stoi'])\n",
    "dep_tag_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'itos': ['<pad>',\n",
       "  '<unk>',\n",
       "  'dep',\n",
       "  'det',\n",
       "  'amod',\n",
       "  'prep',\n",
       "  'advmod',\n",
       "  'nsubj',\n",
       "  'pobj',\n",
       "  'nn',\n",
       "  'ccomp',\n",
       "  'mark',\n",
       "  'dobj',\n",
       "  'cc',\n",
       "  'cop',\n",
       "  'num',\n",
       "  'xcomp',\n",
       "  'advcl',\n",
       "  'aux',\n",
       "  'rcmod',\n",
       "  'csubj',\n",
       "  'discourse',\n",
       "  'neg',\n",
       "  'poss',\n",
       "  'conj',\n",
       "  'pcomp',\n",
       "  'tmod',\n",
       "  'quantmod',\n",
       "  'possessive',\n",
       "  'number',\n",
       "  'prt',\n",
       "  'acomp',\n",
       "  'parataxis',\n",
       "  'npadvmod',\n",
       "  'partmod',\n",
       "  'auxpass',\n",
       "  'expl',\n",
       "  'nsubjpass',\n",
       "  'infmod',\n",
       "  'iobj'],\n",
       " 'stoi': defaultdict(<function __main__._default_unk_index()>,\n",
       "             {'<pad>': 0,\n",
       "              '<unk>': 1,\n",
       "              'dep': 2,\n",
       "              'det': 3,\n",
       "              'amod': 4,\n",
       "              'prep': 5,\n",
       "              'advmod': 6,\n",
       "              'nsubj': 7,\n",
       "              'pobj': 8,\n",
       "              'nn': 9,\n",
       "              'ccomp': 10,\n",
       "              'mark': 11,\n",
       "              'dobj': 12,\n",
       "              'cc': 13,\n",
       "              'cop': 14,\n",
       "              'num': 15,\n",
       "              'xcomp': 16,\n",
       "              'advcl': 17,\n",
       "              'aux': 18,\n",
       "              'rcmod': 19,\n",
       "              'csubj': 20,\n",
       "              'discourse': 21,\n",
       "              'neg': 22,\n",
       "              'poss': 23,\n",
       "              'conj': 24,\n",
       "              'pcomp': 25,\n",
       "              'tmod': 26,\n",
       "              'quantmod': 27,\n",
       "              'possessive': 28,\n",
       "              'number': 29,\n",
       "              'prt': 30,\n",
       "              'acomp': 31,\n",
       "              'parataxis': 32,\n",
       "              'npadvmod': 33,\n",
       "              'partmod': 34,\n",
       "              'auxpass': 35,\n",
       "              'expl': 36,\n",
       "              'nsubjpass': 37,\n",
       "              'infmod': 38,\n",
       "              'iobj': 39,\n",
       "              'root': 1,\n",
       "              'punct': 1,\n",
       "              'mwe': 1,\n",
       "              'appos': 1,\n",
       "              'preconj': 1}),\n",
       " 'len': 40}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_tag_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Pretraining\n",
    "\n",
    "| Metrics\\Datasets      | Twitter | Restaurant | Laptop     | \n",
    "| :---        |    :----:   |  :----:|        ---: |\n",
    "| Precision      | 0.70       | 0.632 | 0.5950  |\n",
    "| Recall   | 0.60        | 0.582 | 0.6069     |\n",
    "| F1   | 0.623        | 0.573 | 0.5919     |\n",
    "| Accuracy   | 0.669        | 0.7366 | 0.6489     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"model/rgat_pretrained.pt\"\n",
    "model = TextGraphAttentionNetwork(args, dep_tag_vocab['len']).to(args.device)\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextGraphAttentionNetwork(\n",
       "  (embed): Embedding(8191, 300)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (tanh): Tanh()\n",
       "  (gate): Gating(\n",
       "    (linear): ModuleList(\n",
       "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "    (gate): ModuleList(\n",
       "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (rnn): GRU(300, 300, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (dep_embed): Embedding(40, 300)\n",
       "  (fc): Linear(in_features=300, out_features=600, bias=True)\n",
       "  (fcs): Sequential(\n",
       "    (0): Linear(in_features=1200, out_features=300, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (fc_final): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (linear): Linear(in_features=600, out_features=600, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training...\n",
      "Num examples = 2313\n",
      "Num Epochs = 30\n",
      "Instantaneous batch size per GPU = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; train_loss: 1.052; eval_loss: 0.9393; eval_acc: 0.5204; eval_f1: 0.3487\n",
      "Epoch: 2; train_loss: 0.8297; eval_loss: 0.7798; eval_acc: 0.663; eval_f1: 0.5709\n",
      "Epoch: 3; train_loss: 0.6906; eval_loss: 0.7486; eval_acc: 0.6693; eval_f1: 0.5626\n",
      "Epoch: 4; train_loss: 0.5673; eval_loss: 0.8583; eval_acc: 0.6505; eval_f1: 0.547\n",
      "Epoch: 5; train_loss: 0.4878; eval_loss: 0.9729; eval_acc: 0.6708; eval_f1: 0.5886\n",
      "Epoch: 6; train_loss: 0.4373; eval_loss: 1.0091; eval_acc: 0.6599; eval_f1: 0.5708\n",
      "Epoch: 7; train_loss: 0.3824; eval_loss: 1.0011; eval_acc: 0.6661; eval_f1: 0.6106\n",
      "Epoch: 8; train_loss: 0.3643; eval_loss: 1.0141; eval_acc: 0.6897; eval_f1: 0.6327\n",
      "Epoch: 9; train_loss: 0.3183; eval_loss: 1.2132; eval_acc: 0.6803; eval_f1: 0.6113\n",
      "Epoch: 10; train_loss: 0.274; eval_loss: 1.2525; eval_acc: 0.6677; eval_f1: 0.596\n",
      "Epoch: 11; train_loss: 0.2651; eval_loss: 1.5822; eval_acc: 0.6912; eval_f1: 0.6288\n",
      "Epoch: 12; train_loss: 0.2833; eval_loss: 1.2333; eval_acc: 0.6755; eval_f1: 0.6061\n",
      "Epoch: 13; train_loss: 0.2678; eval_loss: 1.1428; eval_acc: 0.674; eval_f1: 0.6131\n",
      "Epoch: 14; train_loss: 0.2299; eval_loss: 1.6326; eval_acc: 0.6458; eval_f1: 0.5814\n",
      "Epoch: 15; train_loss: 0.1924; eval_loss: 2.2844; eval_acc: 0.6614; eval_f1: 0.5799\n",
      "Epoch: 16; train_loss: 0.1804; eval_loss: 2.3466; eval_acc: 0.6677; eval_f1: 0.5828\n",
      "Epoch: 17; train_loss: 0.1794; eval_loss: 1.6684; eval_acc: 0.6489; eval_f1: 0.5591\n",
      "Epoch: 18; train_loss: 0.1866; eval_loss: 2.3103; eval_acc: 0.6583; eval_f1: 0.5873\n",
      "Epoch: 19; train_loss: 0.1755; eval_loss: 2.1039; eval_acc: 0.6567; eval_f1: 0.5875\n",
      "Epoch: 20; train_loss: 0.1456; eval_loss: 2.9386; eval_acc: 0.6583; eval_f1: 0.5898\n",
      "Epoch: 21; train_loss: 0.1565; eval_loss: 2.3544; eval_acc: 0.6552; eval_f1: 0.5827\n",
      "Epoch: 22; train_loss: 0.1995; eval_loss: 2.2307; eval_acc: 0.6677; eval_f1: 0.618\n",
      "Epoch: 23; train_loss: 0.1472; eval_loss: 2.2498; eval_acc: 0.652; eval_f1: 0.5839\n",
      "Epoch: 24; train_loss: 0.1323; eval_loss: 2.343; eval_acc: 0.6708; eval_f1: 0.6068\n",
      "Epoch: 25; train_loss: 0.2817; eval_loss: 1.4906; eval_acc: 0.6411; eval_f1: 0.5582\n",
      "Epoch: 26; train_loss: 0.1352; eval_loss: 1.7027; eval_acc: 0.6646; eval_f1: 0.6057\n",
      "Epoch: 27; train_loss: 0.1053; eval_loss: 2.1985; eval_acc: 0.6771; eval_f1: 0.611\n",
      "Epoch: 28; train_loss: 0.1102; eval_loss: 2.1823; eval_acc: 0.6458; eval_f1: 0.5807\n",
      "Epoch: 29; train_loss: 0.114; eval_loss: 2.6881; eval_acc: 0.6379; eval_f1: 0.584\n",
      "Epoch: 30; train_loss: 0.0968; eval_loss: 3.5513; eval_acc: 0.6442; eval_f1: 0.5727\n",
      "Best Eval result is: \n",
      "{'acc': 0.6912225705329154, 'f1': 0.6288450548400856, 'precision': 0.6484404165438648, 'recall': 0.6386280308814428, 'train_loss': 0.2650709149524056, 'eval_loss': 1.5821897268295289, 'epoch': 10}\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "all_eval_results = train(args, train_dataset, model, test_dataset)\n",
    "\n",
    "best_eval_result = max(all_eval_results, key=lambda x: x['acc']) \n",
    "print(\"Best Eval result is: \")\n",
    "print(best_eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
